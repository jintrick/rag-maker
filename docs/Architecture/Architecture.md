# RAGMaker Architecture

## 1. 概要
本文書は、RAG (Retrieval-Augmented Generation) を用いた対話型アプリケーション「RAGMaker」のバックエンドアーキテクチャを定義する。
このシステムは、「外部ソースから情報を自動収集し、RAGデータベースを構築する機能」を中核に据える。

## 2. 操作コマンド
ユーザーはGemini CLIを介して、以下の2つの主要コマンドでシステムを操作する。

*   `/rag <ソースパス>`: **中核機能。** ローカルのドキュメントやWebサイト、GitHubリポジトリから情報を収集し、RAGデータベースを構築・登録する。
*   `/ask <質問文>`: **対話機能。** 登録されたRAGデータベースの中から最適なものを自動で選択し、質問に回答する。

## 3. アーキテクチャ詳細

### 3.1. RAGデータベースの発見と管理
本システムは、複数のRAGデータベースを一元的に管理するため、プロジェクトルートに`discovery.json`ファイルを配置する。

*   **目的:** プロジェクト内に存在するRAGデータベースの場所、タイトル、概要をカタログ化し、`/ask`コマンドが最適なデータベースを動的に選択できるようにする。
*   **構造:** スキーマ、タイトル、ドキュメントリスト（パス、タイトル、要約を含む）などで構成される。
*   **更新:** `/rag`コマンド実行時に自動で追記・更新される。

### 3.2. 中核機能: `/rag` コマンドフロー
このコマンドは、指定されたパス（ローカルディレクトリ、WebページURL、GitHubリポジトリURL）を基に、RAGデータベースを構築し、`discovery.json`に登録するためのプロンプトを呼び出す（`.gemini/commands/rag.toml`に定義される）。プロンプトで定義されるフローは以下のとおりである。

1.  ユーザーが情報ソースのパスを指定し、コマンドを実行する。
2.  LLMは**自らの推論能力を用いて**ソースの種別を判定する
    *   **ローカルディレクトリの場合:** 指定されたディレクトリ内のテキストファイルを収集する。
    *   **Webページの場合:** `download_web_docs`ツールを用いて指定URLの本文より再帰的にリンクを探索・収集する。`html_to_md`ツールを用いてそれらをすべてマークダウンに変換、成功したなら`make_rag_dir`ツールを用いて保存ディレクトリを作成してそこに保存、あとはローカルディレクトリと同様に処理する。
    *   **GitHubリポジトリの場合:** `downlaod_git_docs`ツールを用いてドキュメントファイルのみを抽出したのち、成功したなら`make_rag_dir`ツールを用いて保存ディレクトリを作成してそこに保存、あとはローカルディレクトリと同様に処理する。
3.  `make_vector_db`ツールを使って収集した全テキストデータを処理し、Vector DBを構築する。
    a. テキストをチャンク分割し、ベクトル化される
    b. ソースがローカルディレクトリの場合、そのディレクトリ内に`.chroma/`という隠しディレクトリが作成され、そこにVector DB（ChromaDB）を保存される。
4.  LLMは**自らの推論能力を用いて**収集したドキュメントの内容を基に`title`と`summary`を生成する。
5.  生成した`title`, `summary`と、データベースの`path`を`discovery.json`の`documents`配列に追記または更新する。
6.  構築と登録が完了したことをユーザーに通知する。

### 3.3. 対話機能: `/ask` コマンドフロー
このコマンドは、ユーザーの質問に最も関連性の高いRAGデータベースを自動で選択し、回答を生成する。

1.  ユーザーが `/ask <質問文>` コマンドを実行する。
2.  バックエンドのRAG APIが起動し、まず`discovery.json`を読み込む。
3.  `documents`配列に含まれる全データベースの`title`と`summary`をリストアップする。
4.  リストとユーザーの質問文をLLMに提示し、「どのデータベース（`path`）が質問に回答するのに最も適切か」を選択させる。（**LLM呼び出し1回目**）
5.  `query_vector_db`ツールを使って、選択した`path`とユーザーの質問文`{{args}}`を基にデータベースへ問い合わせ、関連性の高いテキストチャンクを取得する。
6.  取得したチャンクと元の質問文を基に、LLMに最終的な回答を生成させる。（**LLM呼び出し2回目**）
7.  生成された回答がCLIに表示される。


## 4. 使用技術と採用理由

*   **言語: Python**
    *   **理由:** 機械学習やテキスト処理のライブラリが豊富で、RAGシステムの開発に最も適しているため。
*   **HTTPクライアント: `requests`, `BeautifulSoup`**
    *   **理由:** Webページからの情報収集（クローリング）を安定して行うための、実績のある標準的な組み合わせであるため。
*   **Gitクライアント: `GitPython`**
    *   **理由:** `git clone`等の操作をPythonから実行するため。特に、巨大なリポジトリから`docs`ディレクトリのみをダウンロードする**「スパースチェックアウト」**をプログラム的に制御し、データ収集を効率化するために採用する。
*   **Vector DB: `ChromaDB`**
    *   **理由:** セットアップが容易なファイルベースのVector DBであり、迅速なプロトタイピングに適しているため。
*   **テキスト処理・LLM連携: `LangChain`**
    *   **理由:** チャンク分割、ベクトル化、LLMとの対話といった、RAGパイプラインの複雑な処理を抽象化し、開発を効率化するフレームワークであるため。
*   **UI: Gemini CLI**
    *   **理由:** ユーザーとの対話インターフェースとして指定されているため。
