# Issue v0.4.9: ワークフローの抜本的見直しとファイルI/Oの最適化

## 前提知識
- docs/Architecture/Architecture.md
- .gemini/commands/rag.md
- docs/issue/v0.4.7.md (read_fileツールの導入経緯)
- docs/issue/v0.4.8.md (enrich_discoveryツールの導入経緯)

## 経緯
`v0.4.8`で`enrich_discovery`ツールをバッチ処理に対応させ、`discovery.json`への書き込みを効率化しました。しかし、その前段である「ドキュメントのエンリッチ」ステップで、AIエージェントが各ドキュメントの内容を読み込むために`read_file`ツールをループ内で繰り返し呼び出しており、これが深刻なパフォーマンスボトルネックとなっていることが判明しました。

現在のワークフローでは、根本的なI/Oの非効率性を解決できません。

## 現状の問題点
1.  **`read_file`のループ呼び出し**: ドキュメントが100個あれば、`read_file`ツールが100回呼び出され、プロセス起動のオーバーヘッドにより処理が非常に遅くなります。
2.  **ツールの責務過多**: `http_fetch`や`github_fetch`といったデータ取得ツールが、ファイルの取得と`discovery.json`の直接書き込みという2つの責務を持っており、ワークフローの柔軟性を損なっています。

## 解決策の概要
`/rag`コマンドのワークフローと関連ツールのアーキテクチャを抜本的に見直し、ファイルI/Oを最適化します。

**新しいアーキテクチャ方針:**
1.  **データ取得ツールは標準出力へ**: `http_fetch`等のデータ取得ツールは、`discovery.json`をファイルに書き込まず、その内容（JSON文字列）を**標準出力**に返します。
2.  **エージェント主導の一時ファイル運用**: AIエージェントは、標準出力を受け取って一時ファイル（例: `.tmp/discovery.json`）に保存し、エンリッチ処理をすべてその一時ファイルに対して行います。
3.  **最後に配置**: すべての処理が完了した`discovery.json`を、新しい`move_file`ツールを使って最終的な場所（`cache/discovery.json`）に移動させます。

この変更により、AIエージェントがファイルI/Oのタイミングを完全に制御できるようになり、ループ内でのツール呼び出しを排除します。

## 解決策の詳細
この大規模なリファクタリングは、複数のツールの修正・追加を伴います。

1.  **`http_fetch`, `github_fetch` ツールの修正**:
    -   `--output-dir`で指定された場所に`discovery.json`を書き込むロジックを削除します。
    -   代わりに、生成した`discovery.json`の内容をJSON文字列として標準出力に書き出すように変更します。
    -   **注意**: 標準出力への書き込みは、Windowsのエンコーディング問題を回避するため、必ず `src/ragmaker/io_utils.py` の `print_json_stdout` ユーティリティを使用してください。

2.  **`read_file` ツールの拡張 (バッチ読み込み)**:
    -   `--path`引数を複数受け取れるように変更します。（例: `--path file1.md --path file2.md`）
    -   指定されたすべてのファイルの内容を一度に読み込み、`{"contents": [{"path": "...", "content": "..."}, ...]}` のような形式で、単一のJSONオブジェクトとして標準出力に返します。
    -   **注意**: このツールも標準出力にJSONを書き出すため、`print_json_stdout` ユーティリティを使用してください。

3.  **`write_file` ツールの新規作成**:
    -   `--path`と`--content`を引数に取り、指定されたパスに指定された内容を書き込むシンプルなツールを作成します。AIエージェントが標準出力を一時ファイルに保存するために使用します。

4.  **`move_file` ツールの新規作成**:
    -   `--source`と`--destination`を引数に取り、ファイルを移動するツールを作成します。AIエージェントが完成した一時ファイルを最終的な場所に配置するために使用します。

5.  **`.gemini/commands/rag.md` のワークフロー全面改訂**:
    -   AIエージェントが新しいツール群とアーキテクチャを認識できるよう、プロジェクトルートの `discovery.json` を更新します。
        -   `read_file` ツールのパラメータ定義を、複数のパスを受け取れるように配列型 (`"type": "array"`) に修正します。
        -   新しい `write_file` ツールと `move_file` ツールの定義を追加します。

6.  **`.gemini/commands/rag.md` のワークフロー全面改訂**:
    -   「### 4. ドキュメントのエンリッチ」以降のステップを、上記の新しいアーキテクチャに合わせて全面的に書き直します。
    -   **新しいエンリッチフローの骨子**:
        1.  データ取得ツール (`http_fetch`等) の標準出力を `write_file` で `.tmp/discovery.json` に保存する。
        2.  `.tmp/discovery.json` を読み込み、全ドキュメントのパスリストを作成する。
        3.  拡張された `read_file` を**一度だけ**呼び出し、全ドキュメントの内容を一括で取得する。
        4.  メモリ上で全ドキュメントの`title`と`summary`を生成し、`.tmp/discovery.json`の内容（JSONオブジェクト）を更新する。
        5.  `enrich_discovery`（または`write_file`）で、更新したJSONを `.tmp/discovery.json` に書き戻す。
        6.  `move_file` で `.tmp/discovery.json` を `{{kb_root}}/cache/discovery.json` に移動する。

## 参考とすべきスクリプト等
- `src/ragmaker/tools/http_fetch.py`, `src/ragmaker/tools/github_fetch.py` (修正対象)
- `src/ragmaker/tools/read_file.py` (修正対象)
- `.gemini/commands/rag.md` (修正対象)
- `discovery.json` (プロジェクトルートのツールカタログ、修正対象)

## テスト方法
これは大規模な変更のため、各コンポーネントのテストが重要です。

1.  **各ツールの単体テスト**:
    -   `http_fetch`: `discovery.json`をファイルに書き込まず、標準出力にJSONを返すことを確認するテストを追加。
    -   `read_file`: 複数のパスを引数に取り、全ファイル内容を単一のJSONで返すことを確認するテストを追加。
    -   `write_file`, `move_file`: それぞれのファイル操作が正しく行われることを確認する単体テストを新規作成。
2.  **`/rag` コマンドの統合テスト**:
    -   `/rag` コマンドのワークフローを最後まで実行します。
    -   AIエージェントのログを監視し、エンリッチ処理中に`read_file`が一度しか呼び出されていないことを確認します。
    -   `.tmp/`ディレクトリが適切に使用され、最終的に`cache/discovery.json`が正しく生成されていることを確認します。

## 実装状況