# Issue v0.4.15: 本文抽出エンジンの刷新とWeb取得ワークフローの簡素化

## 関連イシュー
- `docs/issue/v0.2.1.md`: 当初、Node.jsへの非依存を決定したイシュー。

## 経緯
プロジェクト初期段階（`v0.2.1`）では、実行環境の簡便性を優先し、Node.jsへの依存を避ける方針を決定しました。その結果、本文抽出にはPythonネイティブで動作する `trafilatura` を採用してきました。

しかし、様々なWebサイトを対象にRAGを構築する中で、`trafilatura`では本文の抽出が不十分なケース（ノイズの混入や本文の欠落）が散見され、これがナレッジベース全体の品質を低下させる大きな要因となっていることが判明しました。

## 現状の問題点
1.  **本文抽出の精度不足**: `trafilatura`では、複雑なレイアウトのWebページから本文、コードブロック、図表などを正確に抽出できず、RAGのソースとして質の低いMarkdownが生成されてしまっている。
2.  **非効率なワークフロー**: 現在のワークフローは、`http_fetch`がHTMLを保存し、後続の`html_to_markdown`がそれをMarkdownに変換するという2段階のプロセスを踏んでおり、冗長である。
3.  **品質のボトルネック**: 本文抽出の精度が、後続の要約生成やベクトル化、最終的な回答生成といったすべてのプロセスの品質の足かせとなっている。
4.  **中途半端な`readabilipy`の利用**: `html_to_markdown.py`では、`readabilipy`を`use_readability=True`で呼び出そうと試みますが、Node.js環境がないために警告を発してフォールバックしており、意図した動作になっていない。

## 解決策の概要
プロジェクトの方針を転換し、**Node.jsおよびnpmを必須の実行環境**と位置づけます。`http_fetch`ツールの責務を「Webページ取得・本文抽出・Markdown変換」まで拡張し、ワークフローを単一のツールで完結できるようにします。

Mozillaが開発しFirefoxのリーダービューでも利用されている、非常に強力な本文抽出エンジン`Readability.js`を、`readabilipy`ライブラリを介して利用することで、本文抽出の精度を大幅に向上させ、RAGナレッジベースの品質を根本から改善します。

**注意**: この変更は `http_fetch` ツールと、それに伴う**Web取得ワークフローの簡素化**に限定されます。`html_to_markdown` ツールは、ローカルディレクトリ内のHTMLファイルを処理するワークフローなどで引き続き必要となるため、**プロジェクトから削除しません。**

## 解決策の詳細
1.  **環境要件の変更**:
    -   `README.md`等のドキュメントを更新し、`rag-maker`の実行にはNode.jsとnpmが必須であることを明記します。

2.  **`http_fetch.py` の修正 (責務の拡張)**:
    -   **依存関係チェックの強化**: ツール実行の最初に `shutil.which('readability')` を使用して `readability-cli` がインストールされ、実行可能かを確認します。見つからない場合は、`io_utils.eprint_error` を使用して「`readability-cli` is not found. Please install it globally via `npm install -g readability-cli`」といった明確なエラーメッセージを標準エラー出力に出力し、異常終了します。
    -   **本文抽出エンジンの変更**: 抽出ロジックを`trafilatura`から`readabilipy`に全面的に切り替えます。`readabilipy.simple_json_from_html_string`を`use_readability=True`で呼び出し、`Readability.js`による高精度な本文抽出（HTML）を強制します。
    -   **Markdown変換機能の追加**: 抽出したHTMLを`markdownify`でMarkdownに変換する処理を追加します。
    -   **出力形式の変更**: 変換したMarkdownを、`--output-dir`で指定されたディレクトリに直接ファイルとして保存します。
    -   **標準出力のJSONフォーマット**: ツールは、後続の処理で利用するため、取得したURLと保存したMarkdownファイルパスのマッピング情報を、以下のJSONフォーマットで標準出力に書き出します。`metadata`には、冗長な`source`キーを削除し、代わりに`fetched_at`を追加します。後続のワークフローで必須となる`url`（収集開始URL）は維持します。
        ```json
        {
          "metadata": {
            "url": "http://example.com/page",
            "base_url": "http://example.com",
            "depth": 5,
            "fetched_at": "2024-05-21T12:34:56.789012Z"
          },
          "documents": [
            {
              "source_url": "http://example.com/page",
              "path": "xxxxxxxx.md"
            }
          ]
        }
        ```
        - `fetched_at`は、`datetime.now(timezone.utc).isoformat()` を使用して生成します。
    -   **`io_utils`の徹底**: ツールが出力するすべての標準出力（JSONレポート）と標準エラー出力（構造化エラー）は、必ず `ragmaker.io_utils` のヘルパー関数 (`print_json_stdout`, `eprint_error` 等) を使用して行うことを徹底します。

## テスト方法
1.  **環境構築**:
    -   Node.jsとnpmがインストールされた環境でテストを実行します。
2.  **`http_fetch.py` の単体テストの堅牢化**:
    -   **目的**: 外部サイトの変更やネットワーク状態に依存しない、安定した単体テストを実装する。
    -   **方針**:
        1.  **HTMLフィクスチャの準備**: 広告、ナビゲーション、フッターなど、本文以外のノイズを意図的に含んだ複雑なHTMLファイル (`test/fixtures/sample_page.html`など) をテスト用の素材として用意する。
        2.  **ローカルHTTPサーバーの利用**: テスト実行時に、Python標準の`http.server`モジュールを使って、上記HTMLフィクスチャを配信する簡易的なHTTPサーバーをバックグラウンドで起動する。
        3.  **ローカルURLへのアクセス**: `http_fetch`ツールには、外部サイトのURLではなく、このローカルサーバーのURL (`http://localhost:8000/sample_page.html`など) を渡す。
    -   **検証項目**:
        -   ツール実行後、出力ディレクトリに高品質なMarkdownファイルが生成されること。
        -   生成されたMarkdownには、HTMLフィクスチャの本文（`<main>`タグの中身など）は含まれているが、ノイズ（`<nav>`や`<footer>`の中身）は除去されていることをアサートで確認する。
        -   `readability-cli` が見つからない場合にツールが適切なエラーメッセージを出して異常終了することもテストする。
        -   ツールが標準出力に書き出すJSONの`metadata`に、`url`, `base_url`, `depth`, `fetched_at` が含まれ、`source`が含まれないことを確認する。
3.  **`/rag` コマンドの統合テスト**: (julesは無視してください)
    -   `/rag`コマンドをWebサイトに対して実行し、最終的に生成されるMarkdownファイルの品質が向上していることを確認する。
    -   **Web取得の**ワークフローから`html_to_markdown`ツールの呼び出しが削除され、`http_fetch`のみで処理が完結することを確認する。

## 実装状況
