# Issue v0.2.1: Webページ取得ツールの実装

## 前提知識
- `docs/Architecture/Architecture.md`

## 現状の問題点
- `/rag` コマンドがWebページから情報を収集する際、指定されたURLのコンテンツを効率的かつ堅牢に取得するツールが存在しない。
- リンクの再帰的な探索や、エラーハンドリング（タイムアウト、接続エラーなど）を考慮する必要がある。

## 解決策の概要
- 指定されたURLのWebページコンテンツを収集するPythonスクリプト `web_fetch.py` を作成する。
- このツールは、`/rag` コマンドのWebページからのデータ収集フローの中核を担う。

## 解決策の詳細
`web_fetch.py` は、以下の仕様を満たすツールとして実装される。

1.  **入力**:
    - `--url`: 取得対象のWebページのURL。
    - `--recursive` (オプション): ページ内のリンクを再帰的に探索し、コンテンツを収集するかどうか（デフォルト: False）。
    - `--depth` (オプション): 再帰探索の最大深度（デフォルト: 1）。
2.  **コンテンツ取得**:
    - `requests` ライブラリなどを使用して、指定されたURLのHTMLコンテンツを取得する。
    - 再帰探索が有効な場合、ページ内のリンクを解析し、指定された深度までコンテンツを収集する。
    - 収集したHTMLコンテンツは、後続の `html_to_markdown.py` で処理されることを想定する。
3.  **結果の出力**: 収集したWebページコンテンツのリストを、JSON形式で標準出力に返す。各エントリには、URLとHTMLコンテンツを含める。
    ```json
    {
      "status": "success",
      "fetched_pages": [
        {
          "url": "...",
          "html_content": "..."
        },
        ...
      ]
    }
    ```
4.  **作法**: エラーハンドリング（HTTPエラー、タイムアウト、接続エラーなど）や引数解析は、既存のツール（例: 旧 `make_vector_db.py`）の堅牢な作法を踏襲する。

## 参考とすべきスクリプト等
- (旧) `make_vector_db.py`: エラーハンドリング、引数解析、JSON出力形式などの作法を参考に。

## テスト方法
`web_fetch.py` の機能が正しく動作することを確認するため、以下のテストを実施する。

1.  **テストURLの準備**: 取得可能なWebページのURLを用意する。
2.  **ツール実行**: `web_fetch.py` を、テストURLを引数として実行する。
    - 例: `python web_fetch.py --url "https://example.com"`
    - 例: `python web_fetch.py --url "https://example.com" --recursive --depth 2`
3.  **出力確認**:
    - 標準出力に、`status: success` を含むJSONが返されることを確認する。
    - `fetched_pages` 配列に、期待されるURLとHTMLコンテンツが含まれていることを確認する。
