# Issue v0.9.0: AI 操縦型ブラウザ（Browser Piloting）への移行

## 前提知識
- `src/ragmaker/tools/browser_fetch.py` (旧実装の参照用)
- `discovery.json` (ツール定義の更新対象)
- `.gemini/commands/rag.md` (プロンプト指示の更新対象)

## 経緯
既存の `browser_fetch` はリンクを機械的に再帰巡回するが、これは Wiki のような巨大かつ複雑なサイトにおいて、ログインページや編集履歴といった不要なページまで取得し、リソースを浪費する原因となっている。AI エージェント（Gemini）がブラウザを直接操縦し、リンクの重要性を判断して選択的に取得を行う「Piloting」方式へ移行することで、収集の質と効率を向上させる。

## 現状の問題点
- 機械的な再帰（Crawl）では、サイト構造に応じた「意味のある選別」が困難。
- `browser_fetch` という単一のスクリプト内ですべて（遷移・抽出・保存）が完結しているため、エージェントが中間に介入して判断を下す余地がない。
- ボット対策画面（CAPTCHA等）に遭遇した際、エージェントが状況を把握し、ユーザーに適切な助けを求めるフローが構築できていない。

## ゴール（完了の定義）
実装担当者は、完了報告前に以下の項目をすべて確認し、チェックを入れ、この文書を更新してcommitすること。
- [x] エージェントがブラウザを操作するための原子的ツール群（`browser_open`, `browser_navigate`, `browser_extract`, `browser_close`）が `src/ragmaker/tools/` に実装されている。
- [x] 各ツールは同一の `user_data_dir`（デフォルト: `.tmp/cache/browser_profile`）を共有し、セッション（クッキー）が維持される。
- [x] `browser_navigate` は遷移先のタイトルと、レンダリング後の有効なリンク一覧（テキストとURLのペア）を JSON で返す。
- [x] `browser_extract` は指定された URL のメインコンテンツを抽出し、Markdown 保存と `catalog.json` への追記（インクリメンタル更新）を 1 アクションで完結させる。
- [x] `discovery.json` に新設ツールの定義が追加され、既存の `browser_fetch` は非推奨（または削除）となっている。
- [x] `rag.md` のワークフローが「AI操縦型（Piloting）」に更新され、エージェントが自律的にリンク選別と抽出を繰り返す指示が含まれている。

## 解決策の概要
`browser_fetch.py` のロジックを分解し、エージェントが「目（リンク確認）」と「手（遷移・抽出）」として使える個別のコマンドへと再構成する。これにより、オーケストレーション層での「判断」を可能にする。Playwright の `launch_persistent_context` を利用して、ツール実行を跨いだセッション維持を実現する。

## 解決策の詳細

### 1. ツール仕様

#### `ragmaker-browser-open`
- **引数**:
  - `--no-headless`: (フラグ) ブラウザを可視状態で起動する場合に指定。
- **標準出力 (JSON)**:
  ```json
  {
    "status": "success",
    "profile_path": ".tmp/cache/browser_profile"
  }
  ```

#### `ragmaker-browser-navigate`
- **引数**:
  - `--url`: (必須) 遷移先URL。
  - `--no-headless`: (フラグ) 必要に応じて手動介入を許可。
- **標準出力 (JSON)**:
  ```json
  {
    "status": "success",
    "url": "現在のURL",
    "title": "ページタイトル",
    "links": [
      {"text": "リンクテキスト1", "href": "URL1"},
      {"text": "...", "href": "..."}
    ],
    "is_bot_detected": false
  }
  ```
- **振る舞い**: ページ遷移後、ネットワークアイドルを待機。ボット検知時は `is_bot_detected: true` を返し、`--no-headless` 時はユーザー入力を待機する。

#### `ragmaker-browser-extract`
- **引数**:
  - `--url`: (必須) 抽出対象URL。
  - `--output-dir`: (必須) MDファイルの保存先。
  - `--no-headless`: (フラグ)
- **標準出力 (JSON)**:
  ```json
  {
    "status": "success",
    "url": "抽出したURL",
    "title": "タイトル",
    "file_path": "保存された相対パス",
    "catalog_updated": true
  }
  ```
- **振る舞い**: 
  - `browser_fetch.py` の抽出ロジック（BeautifulSoup + markdownify）を継承。
  - 保存後、`.tmp/cache/catalog.json` を読み込み、`documents` 配列に自身の結果を追記して保存する。既に同一 URL が存在する場合はスキップまたは更新する。

#### `ragmaker-browser-close`
- **振る舞い**: ブラウザプロセスを確実に終了させる（Playwright のクリーンアップ）。

### 2. セッション共有メカニズム
- すべてのツールは `playwright.async_api.launch_persistent_context` を使用する。
- `user_data_dir` はプロジェクトルートの `.tmp/cache/browser_profile` に固定する。
- ツール実行ごとに context を開き、処理完了後に context を閉じる。これにより、ファイルシステムを介してクッキーやローカルストレージが永続化される。

### 3. `rag.md` の更新計画
「A) Webソースの場合」の中に、以下の「AI Piloting ワークフロー」を組み込む。

```markdown
#### A-2) Wiki/複雑なサイトの場合 (AI Piloting)
1. **ブラウザ初期化**: `browser_open` を実行します。
2. **ナビゲーション**: `browser_navigate --url {{args}}` を実行します。
3. **リンクの選別**: 得られた `links` から、主要な記事やドキュメントと思われるリンクを 5〜10 件選択します。
4. **抽出ループ**: 選択した各リンクに対し、`browser_extract` を実行します。
   - 必要に応じて、さらに深い階層へ `browser_navigate` して探索を続けても構いません。
5. **終了**: `browser_close` を実行します。
```

## 参考とすべきスクリプト等
- `src/ragmaker/tools/browser_fetch.py`: 既存の Playwright 起動、ステレス設定、ボット検知、MD変換ロジックを流用すること。
- `src/ragmaker/utils.py`: `print_catalog_data` 等、カタログ操作の参考。

## テスト方法
実装担当者は、完了報告前に以下の項目をすべて確認し、チェックを入れ、この文書を更新してcommitすること。
- [x] `vtolvr.wiki.gg` に対して `browser_navigate` を実行し、リンク一覧が正しく JSON で返ってくることを確認した。
- [x] 取得したリンクの一つに対して `browser_extract` を実行し、MD ファイルが生成され、`catalog.json` が更新されることを確認した。
- [x] `--no-headless` モードでブラウザが起動し、手動でページを操作した後もツールが継続動作することを確認した。
- [x] `pytest` による各ツールの単体テスト（正常系・異常系）をパスした。

## 実装状況
- [x] ツール群の実装
- [x] discovery.json の更新
- [x] rag.md の更新
- [x] テストの実施
