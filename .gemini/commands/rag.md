ソース（`{{args}}`）をナレッジソースとして取り込みます。
ワークフローに従い、以下のタスクを完了させてください。
ツールの使い方や引数の詳細は`discovery.json`を参照し、自律的に判断して実行してください。

## ツールの実行方法
あなたが利用するツール群は、`pip install -e .` によってシステムにコマンドとしてインストールされています。この仕組みは、`pyproject.toml` の `[project.scripts]` セクションで定義されています。

ツールを実行する際は、プロジェクトルートの `discovery.json` を参照してください。各ツール定義に含まれる `command` キーの値が、この**インストール済みのコマンド名**です。

例えば、`create_knowledge_base` ツールを実行する場合、`discovery.json` から `command` の値である `ragmaker-create-knowledge-base` を取得し、それを直接のコマンドとして、必要な引数を付けて実行してください。

---
## ワークフロー

### 0. ナレッジベースのセットアップ
1.  **ナレッジベースの場所をユーザーに確認する。**
    -   `discovery.json` を参照し、`ask_dir` ツールの `command` (`ragmaker-ask-dir`) を特定する。
    -   `run_shell_command` を使用して、特定したコマンド `ragmaker-ask-dir` を実行する。このツールはGUIのディレクトリ選択ダイアログを表示し、ユーザーが選択したパスをJSON形式で標準出力に返す。
    -   ツールの出力から、選択されたディレクトリのパス (`selected_directory`) を抽出し、これをナレッジベースのルートパス (`kb_root`) とする。
2.  **ナレッジベースの基本構造を作成する。**
    -   取得した `kb_root` を引数として `create_knowledge_base` ツールを実行し、必要なディレクトリと初期ファイルをセットアップする。

**これ以降のすべてのステップでは、このステップで決定した `{{kb_root}}` を基準に、すべてのファイルパスを解決してください。**

### 1. データ取得
ソースの種類に応じて、適切なデータ取得ツール（`http_fetch` や `github_fetch` など）を実行してください。

- **出力先**: 各ツールの出力先ディレクトリとして、`{{kb_root}}/cache/` を指定します。**ソースURLなどに基づいてサブディレクトリを自動生成せず、必ずこのディレクトリ直下にファイルを出力してください。**
- **引数名**: 出力先を指定するための引数名（例: `--output-dir`）は、各ツールの `discovery.json` 定義を参照して自律的に判断してください。

*   **GitHubリポジトリの場合:** `github_fetch`ツールを実行します。
*   **Webページの場合:** `http_fetch`ツールを実行します。
*   **ローカルディレクトリの場合:**
    1.  まず `document_converter` ツールを使い、ソースディレクトリ内のWord, PDF, テキストファイル等をMarkdownに変換し、キャッシュディレクトリに出力します。
    2.  次に `file_sync` ツールを使い、残りのファイル（主に既存のMarkdownファイルや画像など）をキャッシュディレクトリに同期します。

### 2. データ変換
1.  **Markdown変換:** (必要な場合) `html_to_markdown`ツールを実行し、取得したHTMLファイルをMarkdownに変換します。このツールはインプレースで動作します。

### 3. キャッシュクリーンアップ
1.  **不要ファイルの削除:** `cache_cleanup`ツールを実行し、RAGに不要な中間ファイル（HTMLソース、画像など）を削除して、キャッシュディレクトリを整理します。

### 4. ドキュメントのエンリッチ
**注意:** このワークフローでは `read_file` という名前のツールを使用します。Gemini CLIに同名の内蔵ツールが存在する可能性がありますが、必ずこのプロジェクトの `discovery.json` を参照し、そこで定義されているコマンドを実行してください。

1.  **各ドキュメントの要約（バッチ処理）:**
    1.  プロジェクト定義の `read_file` ツールを使って `{{kb_root}}/cache/discovery.json` を読み込みます。
    2.  JSON内の `documents` 配列をループ処理し、各ドキュメントのエンリッチ情報をメモリ上に蓄積します。
        a.  まず、更新内容を格納するための空のリストを、あなたのメモリ上に準備します。
        b.  `documents` 配列をループします。
        c.  ループ内で、`read_file` ツールを使い、各ドキュメントのパス (`path` キー) の内容を読み込みます。
        d.  読み込んだ内容を基に、その**単一ドキュメント**の `title` と `summary` をあなたの推論能力で生成します。
        e.  生成した `path`, `title`, `summary` を持つJSONオブジェクトを作成し、メモリ上のリストに追加します。
    3.  **ループが完了した後**、メモリ上のリストをJSON文字列に変換します。
    4.  `enrich_discovery` ツールを**一度だけ**呼び出し、`--discovery-path` に `{{kb_root}}/cache/discovery.json` を、`--updates` に今生成したJSON文字列を渡して、一括で情報を更新します。

### 5. メタデータ登録
1.  **ナレッジベース全体のメタデータ生成:**
    1.  エンリッチ処理が完了した `{{kb_root}}/cache/discovery.json` を再度、プロジェクト定義の `read_file` ツールで読み込みます。
    2.  `documents` 配列内のすべての `content` を連結し、それを基にナレッジベース全体を表す**単一の** `title` と `summary` をあなたの推論能力で生成します。
2.  **最終登録:**
    1.  `entry_discovery` ツールを呼び出します。`--kb-root` に `{{kb_root}}` を、`--title` と `--summary` には今あなたが生成したものを、`--source-url` と `--src-type` にはワークフローの初期段階で与えられた情報を指定してください。

### 6. 完了報告
1.  **ディレクトリを開く:** `open_directory` ツールを `--path {{kb_root}}` で呼び出し、作成されたナレッジベースのディレクトリをユーザーの画面に表示します。
2.  **ユーザーへのメッセージ:** ツール実行後、以下のメッセージをユーザーに伝えてください。
    > ナレッジベースが作成されました。表示されたウィンドウ内でターミナルを開き、`/ask` コマンドで質問を開始してください。